{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from functools import reduce\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ngiven the source/checkin_checkout_history_updated.csv file, identify the users and its corresponding weeks where it has been acting differently/unusual\\nsteps:\\n1. process the data to group by (user, week) and get {total visits, total length of visits, total calories burnt}\\n    - can use map reduce to do this, or pandas <(user, week), (total visits, total length of visits, total calories burnt)>\\n2. run isoloation forest on the data to identify the outliers for anomoly detection\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "given the source/checkin_checkout_history_updated.csv file, identify the users and its corresponding weeks where it has been acting differently/unusual\n",
    "steps:\n",
    "1. process the data to group by (user, week) and get {total visits, total length of visits, total calories burnt}\n",
    "    - can use map reduce to do this, or pandas <(user, week), (total visits, total length of visits, total calories burnt)>\n",
    "2. run isoloation forest on the data to identify the outliers for anomoly detection\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>calories_burned</th>\n",
       "      <th>session_seconds</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_3291</td>\n",
       "      <td>462</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_1944</td>\n",
       "      <td>1278</td>\n",
       "      <td>9360.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_958</td>\n",
       "      <td>858</td>\n",
       "      <td>5100.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_811</td>\n",
       "      <td>1134</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_4923</td>\n",
       "      <td>1049</td>\n",
       "      <td>6120.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>user_3995</td>\n",
       "      <td>288</td>\n",
       "      <td>2640.0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>user_206</td>\n",
       "      <td>1935</td>\n",
       "      <td>10200.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>user_4983</td>\n",
       "      <td>1312</td>\n",
       "      <td>4380.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>user_1028</td>\n",
       "      <td>787</td>\n",
       "      <td>3420.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>user_3314</td>\n",
       "      <td>512</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          user_id  calories_burned  session_seconds  week\n",
       "0       user_3291              462           2340.0    36\n",
       "1       user_1944             1278           9360.0    15\n",
       "2        user_958              858           5100.0    23\n",
       "3        user_811             1134          10200.0    21\n",
       "4       user_4923             1049           6120.0     8\n",
       "...           ...              ...              ...   ...\n",
       "299995  user_3995              288           2640.0    31\n",
       "299996   user_206             1935          10200.0    26\n",
       "299997  user_4983             1312           4380.0    14\n",
       "299998  user_1028              787           3420.0     9\n",
       "299999  user_3314              512           3000.0     1\n",
       "\n",
       "[300000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/_raw/checkin_checkout_history_updated.csv')\n",
    "df['checkin_time'] = pd.to_datetime(df['checkin_time'])\n",
    "df['checkout_time'] = pd.to_datetime(df['checkout_time'])\n",
    "df['session_seconds'] = (df['checkout_time'] - df['checkin_time']).dt.total_seconds()\n",
    "df['week'] = df['checkin_time'].dt.isocalendar().week\n",
    "# sometimes days in january counted as week 52 so I just changed them to week 0\n",
    "df.loc[(df['checkin_time'].dt.month == 1) & (df['week'] == 52), 'week'] = 0\n",
    "df.drop(['gym_id', 'checkin_time', 'checkout_time', 'workout_type'], axis=1, inplace=True)\n",
    "# lets us know the most recent week we have data from, useful for computing average weekly activity\n",
    "CONSTANT_LAST_WEEK = df['week'].max()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next 2 functions are the basic map-reduce to transform the data into grouping by user/week\n",
    "# and counting how many times they visited in a week + total time + total calories burned\n",
    "\n",
    "# map each entry to key=id+week and value=numVisits,length,calories\n",
    "def mapFunc_groupByUserWeek(row):\n",
    "    _, row_data = row\n",
    "    user_id = row_data['user_id']\n",
    "    calories = int(row_data['calories_burned'])\n",
    "    seconds = int(row_data['session_seconds'])\n",
    "    week = int(row_data['week'])\n",
    "    return (str(user_id) + \"-\" + str(week), (1, seconds, calories))\n",
    "\n",
    "# reduce by summing, to calculate users gym activity by week\n",
    "def reduceFunc_groupByUserWeek(acc, pair):\n",
    "    key, value = pair\n",
    "    if key in acc:\n",
    "        acc[key] = tuple(map(lambda x, y: x + y, acc[key], value))\n",
    "    else:\n",
    "        # i think they're already ints after the changes I made above\n",
    "        acc[key] = (int(value[0]), int(value[1]), int(value[2]))\n",
    "    return acc   \n",
    "\n",
    "\n",
    "# if a user doesn't go in a whole week, we still need an empty entry for that week for our anomaly detection\n",
    "# so I'm going to find the first week each user started going to the gym so we can add every week after\n",
    "\n",
    "# map each entry to key=id and value=week\n",
    "def mapFunc_addEmptyWeeks(row):\n",
    "    _, entry = row\n",
    "    key = entry['user_id']\n",
    "    value = int(entry['week'])\n",
    "    return (key, value)\n",
    "\n",
    "# reduce by taking the first week they started going to the gym\n",
    "def reduceFunc_findFirstWeek(acc, pair):\n",
    "    key, value = pair\n",
    "    if key in acc:\n",
    "        acc[key] = min(acc[key] , value)\n",
    "    else:\n",
    "        acc[key] = value\n",
    "    return acc\n",
    "\n",
    "# this reduce function will add all the empty weeks \n",
    "# and the output will be the starting dictionary inputted to reduceFunc_groupByUserWeek\n",
    "def reduceFunc_addEmptyWeeks(acc, pair):\n",
    "    user, firstWeek = pair\n",
    "    for i in range(firstWeek, CONSTANT_LAST_WEEK + 1):\n",
    "        acc[user + '-' + str(i)] = (0, 0, 0)\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up empty weeks first\n",
    "mappedData_addEmptyWeeks = list(map(mapFunc_addEmptyWeeks, df.iterrows()))\n",
    "\n",
    "userlyFirstWeek = reduce(reduceFunc_findFirstWeek, mappedData_addEmptyWeeks, {})\n",
    "emptyWeeks = reduce(reduceFunc_addEmptyWeeks, userlyFirstWeek.items(), {})\n",
    "\n",
    "#mapped_data = map(rowToTuple, df.iterrows())\n",
    "#reduced_data = reduce(reduceTuple, mapped_data, {})\n",
    "#reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now adding all the actual information to the \"empty weeks\" dict returned from above cell\n",
    "mappedData_groupByUserWeek = list(map(mapFunc_groupByUserWeek, df.iterrows()))\n",
    "\n",
    "weekly_userly_data = reduce(reduceFunc_groupByUserWeek, mappedData_groupByUserWeek, emptyWeeks)\n",
    "weekly_userly_data_dict = dict(weekly_userly_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_df = pd.DataFrame.from_dict(reduced_data, orient='index', columns=['total_sessions', 'total_session_seconds', 'total_calories'])\n",
    "# # csv_df = csv_df.reset_index()\n",
    "\n",
    "# csv_df.to_csv('processed_data.csv', index=True)\n",
    "# csv_df\n",
    "\n",
    "# storing both dict version and other version NOTE: do not need to store in files as we can just use the variables\n",
    "# with open(\"groupByUserWeek.json\", \"w\") as file:\n",
    "#     json.dump(weekly_userly_data, file)\n",
    "\n",
    "# with open(\"groupByUserWeek_dict.json\", \"w\") as file:\n",
    "#     json.dump(weekly_userly_data_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>total_sessions</th>\n",
       "      <th>total_session_seconds</th>\n",
       "      <th>total_calories</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th>week</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">user_3291</th>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>9540</td>\n",
       "      <td>2552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>12420</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3060</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7440</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>3360</td>\n",
       "      <td>930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">user_3522</th>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>14040</td>\n",
       "      <td>1937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>5100</td>\n",
       "      <td>1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>9180</td>\n",
       "      <td>1654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>1</td>\n",
       "      <td>6420</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204778 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                total_sessions  total_session_seconds  total_calories\n",
       "user_id   week                                                       \n",
       "user_3291 1                  2                   9540            2552\n",
       "          2                  2                  12420             528\n",
       "          3                  1                   3060             545\n",
       "          4                  1                   7440             561\n",
       "          5                  1                   3360             930\n",
       "...                        ...                    ...             ...\n",
       "user_3522 37                 2                  14040            1937\n",
       "          38                 0                      0               0\n",
       "          39                 1                   5100            1469\n",
       "          40                 1                   9180            1654\n",
       "          41                 1                   6420             875\n",
       "\n",
       "[204778 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# turn jsons into a df, then run the anomoly forest on it\n",
    "\n",
    "transformed_data = [\n",
    "    (*key.split('-'), *values) for key, values in weekly_userly_data.items()\n",
    "]\n",
    "\n",
    "cleaned_dataframe = pd.DataFrame(transformed_data, columns=['user_id', 'week', 'total_sessions', 'total_session_seconds', 'total_calories'])\n",
    "cleaned_dataframe.set_index(['user_id', 'week'], inplace=True)\n",
    "\n",
    "cleaned_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dataframe_with_anomoly = cleaned_dataframe.copy()\n",
    "model = IsolationForest(contamination=0.05, random_state=42)\n",
    "cleaned_dataframe_with_anomoly['anomaly'] = model.fit_predict(cleaned_dataframe_with_anomoly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after performing anomaly detection we want to see how relevent each anomaly is\n",
    "# going to use a modified TF.IDF where each document is a users list of anomaly weeks\n",
    "# and each word is a week, but instead of the week appearing a lot, we're going to use distance from mean\n",
    "# this will allow us to see how extreme of an anomaly it is, and if it's common among all users\n",
    "# perhaps everyones gym usage went down cause there was a holiday\n",
    "\n",
    "def mapFunc_findUserMean(row):\n",
    "    key_old,value_old = row\n",
    "    user, week = key_old.split('-')\n",
    "    value_new = (int(week), value_old[0], value_old[1], value_old[2])\n",
    "    return (user, value_new)\n",
    "\n",
    "def reduceFunc_sumStats_minWeek(acc, pair):\n",
    "    key, value = pair\n",
    "    if key in acc:\n",
    "        #take minimum week to find when they started, sum rest of the values\n",
    "        acc[key] = ( min(acc[key][0] , value[0]) , \n",
    "                    acc[key][1] + value[1] , \n",
    "                    acc[key][2] + value[2] , \n",
    "                    acc[key][3] + value[3] )\n",
    "    else:\n",
    "        acc[key] = (value[0], value[1], value[2], value[3])\n",
    "\n",
    "    return acc\n",
    "        \n",
    "def reduceFunc_averageStats(acc, pair):\n",
    "    key, value = pair\n",
    "    numWeeks = CONSTANT_LAST_WEEK - value[0] + 1\n",
    "    acc[key] = (value[1] / numWeeks, value[2] / numWeeks, value[3] / numWeeks)\n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappedData_findUserMean = list(map(mapFunc_findUserMean, weekly_userly_data_dict.items()))\n",
    "\n",
    "weekly_userly_total = reduce(reduceFunc_sumStats_minWeek, mappedData_findUserMean, {})\n",
    "weekly_userly_mean = reduce(reduceFunc_averageStats, dict(weekly_userly_total).items(), {})\n",
    "\n",
    "weekly_userly_mean_dict = dict(weekly_userly_mean)\n",
    "\n",
    "#print(weekly_userly_mean_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"averageByUser.json\", \"w\") as file:\n",
    "    json.dump(weekly_userly_mean, file)\n",
    "\n",
    "with open(\"averageByUser_dict.json\", \"w\") as file:\n",
    "    json.dump(weekly_userly_mean_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Okay for TF.IDF the TF part is supposed to be a number between 0-1 but distance from mean might not be\n",
    "# So I think I'm going to find the max distance from the minimum box containing the data and compute the \n",
    "# max distance from any vertex to mean and divide the actual distance by that\n",
    "\n",
    "# then we need to actually comput IDF for each week \n",
    "# which doesn't need to be repeated for each user since it's always the same\n",
    "\n",
    "# then we need to compute TF' for each user/week\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
